
set -ex

{% if ceph_salt_git_repo and ceph_salt_git_branch %}
# install ceph-salt
cd /root
git clone {{ ceph_salt_git_repo }}
cd ceph-salt
zypper --non-interactive install autoconf gcc python3-devel python3-pip python3-curses

{% if ceph_salt_fetch_github_pr_heads %}
# fetch the available PRs (HEAD) from github. With that, "ceph_salt_git_branch" can be something like "origin/pr/127" to checkout a github PR
git fetch origin "+refs/pull/*/head:refs/remotes/origin/pr/*"
{% endif %}
{% if ceph_salt_fetch_github_pr_merges %}
# fetch the available PRs (MERGE) from github. With that, "ceph_salt_git_branch" can be something like "origin/pr-merged/127" to checkout a github PR
git fetch origin "+refs/pull/*/merge:refs/remotes/origin/pr-merged/*"
{% endif %}

git checkout {{ ceph_salt_git_branch }}

pip install --prefix /usr .
# install ceph-salt-formula
cp -r ceph-salt-formula/salt/* /srv/salt/
chown -R salt:salt /srv
{% else %}
# ceph-salt-formula is installed automatically as a dependency of ceph-salt
zypper --non-interactive install ceph-salt
{% endif %}

systemctl restart salt-master
{% include "wait_for_minions.sh.j2" %}

{% if stop_before_ceph_salt_config %}
exit 0
{% endif %}

echo "PATH is $PATH"
type ceph-salt

MON_NODES_COMMA_SEPARATED_LIST=""
MGR_NODES_COMMA_SEPARATED_LIST=""
MDS_NODES_COMMA_SEPARATED_LIST=""
{% for node in nodes %}
{% if node.has_roles() and not node.has_exclusive_role('client') %}
ceph-salt config /ceph_cluster/minions add {{ node.fqdn }}
ceph-salt config /ceph_cluster/roles/admin add {{ node.fqdn }}
{% endif %}
{% if node.has_role('bootstrap') %}
ceph-salt config /ceph_cluster/roles/bootstrap set {{ node.fqdn }}
{% endif %}
{% if node.has_role('mon') %}
MON_NODES_COMMA_SEPARATED_LIST+="{{ node.name }},"
{% endif %}
{% if node.has_role('mgr') %}
MGR_NODES_COMMA_SEPARATED_LIST+="{{ node.name }},"
{% endif %}
{% if node.has_role('mds') %}
MDS_NODES_COMMA_SEPARATED_LIST+="{{ node.name }},"
{% endif %}
{% endfor %}
MON_NODES_COMMA_SEPARATED_LIST="${MON_NODES_COMMA_SEPARATED_LIST%,*}"
MGR_NODES_COMMA_SEPARATED_LIST="${MGR_NODES_COMMA_SEPARATED_LIST%,*}"
MDS_NODES_COMMA_SEPARATED_LIST="${MDS_NODES_COMMA_SEPARATED_LIST%,*}"

ceph-salt config /system_update/packages disable
ceph-salt config /system_update/reboot disable
ceph-salt config /ssh/ generate
{% if image_path %}
ceph-salt config /containers/images/ceph set {{ image_path }}
{% endif %}
{% set external_timeserver = "pool.ntp.org" %}
ceph-salt config /time_server/server_hostname set {{ external_timeserver }}

{% if ceph_salt_deploy_osds %}
{% if storage_nodes < 3 %}
ceph-salt config /cephadm_bootstrap/ceph_conf add global
ceph-salt config /cephadm_bootstrap/ceph_conf/global set "osd crush chooseleaf type" 0
{% endif %}
{% endif %} {# if ceph_salt_deploy_osds #}

ceph-salt config /cephadm_bootstrap/dashboard/username set admin
ceph-salt config /cephadm_bootstrap/dashboard/password set admin

ceph-salt config ls
ceph-salt export --pretty
ceph-salt status

zypper repos -upEP
zypper info cephadm | grep -E '(^Repo|^Version)'
ceph-salt --version

{% if stop_before_ceph_salt_deploy %}
exit 0
{% endif %}

{% if use_salt %}
salt -G 'ceph-salt:member' state.apply ceph-salt
{% else %}
stdbuf -o0 ceph-salt -ldebug apply --non-interactive
{% endif %}

{% if ceph_salt_deploy_mons %}
{% if mon_nodes > 1 %}
TIME_SERVER="$(ceph-salt export | jq -r .time_server.server_host)"
{% set chrony_script = "chrony_sync_start.sh" %}
cat > /root/{{ chrony_script }} << 'EOF'
#!/bin/bash

set -x

function try_wait {
    local cmd="$1"
    local tries="$2"
    local sleep_secs="$3"
    set +x
    for i in $(seq 1 "$tries") ; do
        set -x
        $cmd
        set +x
        SAVED_STATUS="$?"
        test "$SAVED_STATUS" = "0" && break
        set -x
        sleep "$sleep_secs"
        set +x
    done
    set -x
}

chronyc 'burst 4/4'
sleep 15
chronyc makestep
stdbuf -o0 chronyc waitsync 30 0.04
try_wait "chronyc -n sources" 10 5
systemctl status --lines 20 chronyd.service | grep stepped
chronyc tracking
EOF
chmod 755 /root/{{ chrony_script }}
{% for _node in nodes %}
{% if _node != master %}
scp -o StrictHostKeyChecking=no /root/{{ chrony_script }} {{ _node.name }}:
{% endif %}
{% endfor %}
{% for _node in nodes %}
if [ "{{ _node.fqdn }}" == "$TIME_SERVER" ] ; then
    ssh -o StrictHostKeyChecking=no {{ _node.name }} ./{{ chrony_script }}
fi
{% endfor %}
{% for _node in nodes %}
if [ "{{ _node.fqdn }}" != "$TIME_SERVER" ] ; then
    ssh -o StrictHostKeyChecking=no {{ _node.name }} ./{{ chrony_script }} &
fi
{% endfor %}
wait
ceph orch apply mon "$MON_NODES_COMMA_SEPARATED_LIST"
{% endif %} {# mon_nodes > 1 #}
{% endif %} {# ceph_salt_deploy_mons #}

{% if ceph_salt_deploy_mgrs %}
{% if mgr_nodes > 1 %}
ceph orch apply mgr "$MGR_NODES_COMMA_SEPARATED_LIST"
{% endif %} {# mgr_nodes > 1 #}
{% endif %} {# ceph_salt_deploy_mgrs #}

{% if ceph_salt_deploy_osds %}
ceph orch device ls --refresh
{% for node in nodes %}
{% if node.has_role('storage') %}
echo "{\"service_type\": \"osd\", \"placement\": {\"host_pattern\": \"{{ node.name }}*\"}, \"service_id\": \"testing_dg_{{ node.name }}\", \"data_devices\": {\"all\": True}}" | ceph orch apply osd -i -
{% endif %}
{% endfor %}
{% endif %} {# if ceph_salt_deploy_osds #}

{% if ceph_salt_deploy_mdss %}
ceph fs volume create myfs "$MDS_NODES_COMMA_SEPARATED_LIST"
{% endif %} {# if ceph_salt_deploy_mdss #}

{% include "qa_test.sh.j2" %}
